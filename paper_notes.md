## Detecting Click Fraud in Online Advertising: A Data Mining Approach

### Задача
Обнаружение мошеннических кликов в рекламной сети. Как по информации за три дня обнаружить фрод в другие 3 дня?

### Оценка качества
Average precision. Метрика предпочитает алгоритмы, которые ставят в топ небольшое количество полезных элементов выборки. Соответствует площади под ROC кривой
### Методы
1. 
#### Разработка признаков
Признаки описывают
* просто клики (например, общее количество)
* повторные клики (например, количество дублированных url в минуту ночью)
* клики с высоким риском (например, для топ-10 стран по фроду)
#### Алгоритм
Обобщенный градиентный бустинг

2.
#### Разработка признаков
Статистика количества кликов по разным промежуткам времен, по IP
#### Метод
Пытались делать ресемплинг, но получилось хуже 
Классификатор, полученный усреднением 
* бустинга деревьев
* бэггинга деревьев
* метода случайных подпространств и др.

3.
Статистика количества кликов с одного IP с разными промежутками времени
Аналогично для кликов с одной и той же кампанией, а также для комбинации IP-агент (в надежде, что это идентифицирует лучше, чем просто IP). 

#### Метод
1. Выбираем отдельную валидационную выборку.
2. Выбираем на ней лучшие гиперпараметры
3. Обучаем модель с лучшими гиперпараметрами на обучающем *и валидационном*
множествах

##### Алгоритмы
* Одиночные
    - RPROP
    - FT tree, etc.
* Антсамбли
    - tree ensemble
    - random forest, etc. 

4. 
#### Извлечение признаков
Считаем click profile: смотрим на последовательные клики, вычисляем зазор между соседями, строим гистограмму по этим зазорам.
#### Метод
Ensemble of random forests 
5.
#### Извлечение признаков
* Базовая статистика по площадкам
* Пространственные признаки (по стране, URL, устройству)
* Признаки, полученные из временных рядов

#### Метод
##### Классификаторы
* Одиночные: 
    - логистическая регрессия 
    - SVM c весами классов, обратно пропорциональными их распространенности
    - kNN
* Ансамбли:
    - Random forest
    - Gradient boosting
    - Extra trees

##### Исключение признаков
* Сортируем признаки по важности (например, из весов модели).
* Итеративно пытаемся исключить префиксы списка признаков

### Выводы
* Приведенные методы плохо справляются с групповым мошенничеством -- на помощь приходит изучение структуры (графы!)
* С изменением стратегий мошенников приходится переучивать модели заново -- можно попробовать online learning
* Transfer learning ?

### Мои наблюдения
* Постановка задачи не позволяет выделить мошеннические *клики*, вместо этого мы находим нечестные площадки. Это нежелательно, если, например, конкуренты пытаются выставить площадку в невыгодном свете.
* Т.к. я работаю с данными соцсети, мне не надо извращаться, например, с комбинацией ip + device_user_agent для идентификации. Хотя все равно за сотней аккаунтов может стоять один реальный человек.
